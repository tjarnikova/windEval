{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f5e9cd",
   "metadata": {},
   "source": [
    "### aim: Fig-means-extremes, Table-means-clim-and-trend Table-extremes-clim-and-trend\n",
    "\n",
    "### associated scripts:\n",
    "\n",
    "- means timeseries made in windEval/plottingCode/extract_ts.py  and extract_ts_2019.py which needs to be run in the pyxr env, which has a UKESM-compatible xarray\n",
    "- trends calculated in windEval/plottingCode/trend_table.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aefa5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc8f133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71575c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cmocean import cm\n",
    "import cartopy as cp\n",
    "import cartopy.crs as ccrs\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "import cartopy.feature as cfeature\n",
    "from importlib import reload\n",
    "import matplotlib.path as mpath\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seawater\n",
    "import time\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "font = {'family' : 'normal',\n",
    "'weight' : 'normal',\n",
    "'size'   : 13}\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a5426",
   "metadata": {},
   "source": [
    "## Calculate seasonal mean climatology (for table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465fbe0",
   "metadata": {},
   "source": [
    "these seasonal climatologies are calculated in Fig-spat-clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a9f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir = '/gpfs/data/greenocean2/software/products/windsFromComponents/dailyStandard/intProc/'\n",
    "\n",
    "\n",
    "merradjf = xr.open_dataset(f'{sdir}/MERRA_djf_1980-2019.nc')\n",
    "merrajja = xr.open_dataset(f'{sdir}/MERRA_jja_1980-2019.nc')\n",
    "merrason = xr.open_dataset(f'{sdir}/MERRA_son_1980-2019.nc')\n",
    "merramam = xr.open_dataset(f'{sdir}/MERRA_mam_1980-2019.nc')\n",
    "merrafy = xr.open_dataset(f'{sdir}/MERRA_fy_1980-2019.nc')\n",
    "\n",
    "doedjf = xr.open_dataset(f'{sdir}/NCEP-DOE_djf_1980-2019.nc')\n",
    "doejja = xr.open_dataset(f'{sdir}/NCEP-DOE_jja_1980-2019.nc')\n",
    "doeson = xr.open_dataset(f'{sdir}/NCEP-DOE_son_1980-2019.nc')\n",
    "doemam = xr.open_dataset(f'{sdir}/NCEP-DOE_mam_1980-2019.nc')\n",
    "doefy = xr.open_dataset(f'{sdir}/NCEP-DOE_fy_1980-2019.nc')\n",
    "\n",
    "ncardjf = xr.open_dataset(f'{sdir}/NCEP-NCAR_djf_1980-2019.nc')\n",
    "ncarjja = xr.open_dataset(f'{sdir}/NCEP-NCAR_jja_1980-2019.nc')\n",
    "ncarson = xr.open_dataset(f'{sdir}/NCEP-NCAR_son_1980-2019.nc')\n",
    "ncarmam = xr.open_dataset(f'{sdir}/NCEP-NCAR_mam_1980-2019.nc')\n",
    "ncarfy = xr.open_dataset(f'{sdir}/NCEP-NCAR_fy_1980-2019.nc')\n",
    "\n",
    "eradjf = xr.open_dataset(f'{sdir}/ERA5_djf_1980-2019.nc')\n",
    "erajja = xr.open_dataset(f'{sdir}/ERA5_jja_1980-2019.nc')\n",
    "erason = xr.open_dataset(f'{sdir}/ERA5_son_1980-2019.nc')\n",
    "eramam = xr.open_dataset(f'{sdir}/ERA5_mam_1980-2019.nc')\n",
    "erafy = xr.open_dataset(f'{sdir}/ERA5_fy_1980-2019.nc')\n",
    "\n",
    "ukesmdjf = xr.open_dataset(f'{sdir}/UKESM_djf_1980-2019.nc')\n",
    "ukesmjja = xr.open_dataset(f'{sdir}/UKESM_jja_1980-2019.nc')\n",
    "ukesmson = xr.open_dataset(f'{sdir}/UKESM_son_1980-2019.nc')\n",
    "ukesmmam = xr.open_dataset(f'{sdir}/UKESM_mam_1980-2019.nc')\n",
    "ukesmfy = xr.open_dataset(f'{sdir}/UKESM_fy_1980-2019.nc')\n",
    "\n",
    "JRAdjf = xr.open_dataset(f'{sdir}/JRA_djf_1980-2019.nc')\n",
    "JRAjja = xr.open_dataset(f'{sdir}/JRA_jja_1980-2019.nc')\n",
    "JRAson = xr.open_dataset(f'{sdir}/JRA_son_1980-2019.nc')\n",
    "JRAmam = xr.open_dataset(f'{sdir}/JRA_mam_1980-2019.nc')\n",
    "JRAfy = xr.open_dataset(f'{sdir}/JRA_fy_1980-2019.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26027dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "savenam = '/gpfs/home/mep22dku/scratch/SOZONE/windAnalyis/wspdComponents/PlankTOMmask_regridrecalc.nc'\n",
    "cdomask = xr.open_dataset(savenam)\n",
    "cdomask\n",
    "tmask = cdomask.tmask\n",
    "sh = False\n",
    "if sh:\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(tmask)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(erafyws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2fa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = False\n",
    "if ex:\n",
    "    data = np.zeros([5,6])\n",
    "    \n",
    "    data[0,0] = (np.average(ncarfy.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[1,0] = (np.average(ncardjf.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[2,0] = (np.average(ncarmam.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[3,0] = (np.average(ncarjja.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[4,0] = (np.average(ncarson.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "\n",
    "    data[0,1] = (np.average(doefy.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[1,1] = (np.average(doedjf.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[2,1] = (np.average(doemam.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[3,1] = (np.average(doejja.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[4,1] = (np.average(doeson.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "\n",
    "    data[0,2] = (np.average(merrafy.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[1,2] = (np.average(merradjf.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[2,2] = (np.average(merramam.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[3,2] = (np.average(merrajja.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[4,2] = (np.average(merrason.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "\n",
    "    data[0,3] = (np.average(JRAfy.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[1,3] = (np.average(JRAdjf.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[2,3] = (np.average(JRAmam.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[3,3] = (np.average(JRAjja.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[4,3] = (np.average(JRAson.wspd10m[30:50,:], weights=tmask[30:50,:]))    \n",
    "\n",
    "    data[0,4] = (np.average(erafy.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[1,4] = (np.average(eradjf.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[2,4] = (np.average(eramam.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[3,4] = (np.average(erajja.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[4,4] = (np.average(erason.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    \n",
    "    data[0,5] = (np.average(ukesmfy.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[1,5] = (np.average(ukesmdjf.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[2,5] = (np.average(ukesmmam.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[3,5] = (np.average(ukesmjja.wspd10m[30:50,:], weights=tmask[30:50,:]))\n",
    "    data[4,5] = (np.average(ukesmson.wspd10m[30:50,:], weights=tmask[30:50,:]))   \n",
    "\n",
    "    df = pd.DataFrame(data, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                      index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "    df.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "    df.to_csv(f'./plts/allmod_mn_windspeed_1980-2019_60-40S.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a564d7",
   "metadata": {},
   "source": [
    "## This code calculates mean of all winds above 95%\n",
    "\n",
    "The extreme winds are calculated as follows:\n",
    "For each day in a year, the 95% of all winds below 30S is calculated and a weighted average is taken of winds above this percentile. For a seasonal extreme winds for a given year, the mean of this timeseries is taken. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f253291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_quantile(values, quantiles, sample_weight=None, \n",
    "                      values_sorted=False, old_style=False):\n",
    "    \"\"\" Very close to numpy.percentile, but supports weights.\n",
    "    NOTE: quantiles should be in [0, 1]!\n",
    "    :param values: numpy.array with data\n",
    "    :param quantiles: array-like with many quantiles needed\n",
    "    :param sample_weight: array-like of the same length as `array`\n",
    "    :param values_sorted: bool, if True, then will avoid sorting of\n",
    "        initial array\n",
    "    :param old_style: if True, will correct output to be consistent\n",
    "        with numpy.percentile.\n",
    "    :return: numpy.array with computed quantiles.\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    quantiles = np.array(quantiles)\n",
    "    if sample_weight is None:\n",
    "        sample_weight = np.ones(len(values))\n",
    "    sample_weight = np.array(sample_weight)\n",
    "    assert np.all(quantiles >= 0) and np.all(quantiles <= 1), \\\n",
    "        'quantiles should be in [0, 1]'\n",
    "\n",
    "    if not values_sorted:\n",
    "        sorter = np.argsort(values)\n",
    "        values = values[sorter]\n",
    "        sample_weight = sample_weight[sorter]\n",
    "\n",
    "    weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n",
    "    if old_style:\n",
    "        # To be convenient with numpy.percentile\n",
    "        weighted_quantiles -= weighted_quantiles[0]\n",
    "        weighted_quantiles /= weighted_quantiles[-1]\n",
    "    else:\n",
    "        weighted_quantiles /= np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_quantiles, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42563afa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383c76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ex = False\n",
    "\n",
    "def get_extrema(tvar,yr):\n",
    "    tn = '/gpfs/home/mep22dku/scratch/SOZONE/windAnalyis/wspdComponents/PlankTOMmask_regridrecalc.nc'\n",
    "    cdomask = xr.open_dataset(tn)\n",
    "    adir = '/gpfs/data/greenocean2/software/products/windsFromComponents/dailyStandard/'    \n",
    "    w = xr.open_dataset(f'{adir}/{tvar}/{tvar}_wind_daily_1x1_{yr}.nc')\n",
    "\n",
    "    at95 = np.zeros([len(w.time_counter)])\n",
    "    above95 = np.zeros([len(w.time_counter)])\n",
    "    above95wt = np.zeros([len(w.time_counter)])\n",
    "    tmask = cdomask.tmask[30:50,:].values\n",
    "\n",
    "    for i in range(0,len(w.time_counter)):\n",
    "\n",
    "        twspd = w.wspd10m[i,30:50,:]\n",
    "        where0 = np.where(tmask == 0)\n",
    "        twspd2 = np.copy(twspd)\n",
    "        twspd2[np.where(tmask == 0)] = np.nan\n",
    "        perc95 = weighted_quantile(np.ravel(twspd), 0.95, \\\n",
    "                                sample_weight=np.ravel(tmask))\n",
    "\n",
    "        tmask2 = np.copy(tmask)\n",
    "        ts = twspd2[twspd2>perc95]\n",
    "        q = np.where(twspd2 < perc95)\n",
    "        tmask2[q] = 0\n",
    "\n",
    "        at95[i] = perc95\n",
    "        above95wt[i] = np.average(np.ravel(twspd), weights = np.ravel(tmask2))\n",
    "        above95[i] = np.nanmean(twspd2[twspd2>perc95])\n",
    "\n",
    "    savenam = f'{adir}/intProc/{tvar}_windex_{yr}.nc'\n",
    "    print(savenam)\n",
    "    data_vars = {'at95':(['time_counter'], at95,\n",
    "    {'units': 'm/s',\n",
    "    'long_name':'daily 95% of winds south of 40S to 60s'}),\n",
    "                 'above95':(['time_counter'], above95,\n",
    "    {'units': '',\n",
    "    'long_name':''}),\n",
    "                 'above95wt':(['time_counter'], above95wt,\n",
    "    {'units': '',\n",
    "    'long_name':'mean of everything above 95wt'}),\n",
    "    }\n",
    "    # define coordinates\n",
    "    coords = {'time_counter': (['time_counter'], w.time_counter),\n",
    "            }\n",
    "    # define global attributes\n",
    "    attrs = {'made in':'windEval/plottingCode/Fig-means-extremes.ipynb',\n",
    "    'desc': ''\n",
    "    }\n",
    "    ds = xr.Dataset(data_vars=data_vars,\n",
    "    coords=coords,\n",
    "    attrs=attrs)\n",
    "    ds.to_netcdf(savenam)\n",
    "\n",
    "tits = ['JRA']#,'NCEP-DOE']#,'ERA5','NCEP-NCAR','UKESM']\n",
    "\n",
    "if ex:\n",
    "\n",
    "    for yr in range(1940,2024):\n",
    "        for t in tits:\n",
    "            try:\n",
    "                get_extrema(t,yr)\n",
    "            except:\n",
    "                print(f'haha no for {t}, {yr}')\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752198a1",
   "metadata": {},
   "source": [
    "## claculate seasonal extreme climatology (for table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993cc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_exlist(prod,yrst = 1980, yrend = 2019, \\\n",
    "                 baseDir = '/gpfs/data/greenocean2/software/products/windsFromComponents/dailyStandard/intProc/'):\n",
    "    yrs = np.arange(yrst,yrend+1,1)\n",
    "    ylist = []\n",
    "    for i in range(0,len(yrs)):\n",
    "        ty = f'{baseDir}/{prod}_windex_{yrs[i]}.nc'\n",
    "        t2 = glob.glob(ty)\n",
    "        #print(t2)\n",
    "        ylist.append(t2[0])\n",
    "    return ylist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc54faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MERRAex = xr.open_mfdataset(make_exlist('MERRA'))\n",
    "ERA5ex = xr.open_mfdataset(make_exlist('ERA5'))\n",
    "NCEPDOEex = xr.open_mfdataset(make_exlist('NCEP-DOE'))\n",
    "NCEPNCARex = xr.open_mfdataset(make_exlist('NCEP-NCAR'))\n",
    "UKESMex = xr.open_mfdataset(make_exlist('UKESM'))\n",
    "JRAex = xr.open_mfdataset(make_exlist('JRA'))\n",
    "\n",
    "tdarx = [ERA5ex, NCEPNCARex, MERRAex, NCEPDOEex, UKESMex, JRAex]\n",
    "\n",
    "UKESMex_FY = (UKESMex.above95wt.mean(dim = ['time_counter']).values)\n",
    "UKESMex_DJF = (UKESMex.above95wt.sel(time_counter=(UKESMex['time_counter.season'] == 'DJF')).mean(dim = ['time_counter']).values)\n",
    "UKESMex_MAM = (UKESMex.above95wt.sel(time_counter=(UKESMex['time_counter.season'] == 'MAM')).mean(dim = ['time_counter']).values)\n",
    "UKESMex_JJA = (UKESMex.above95wt.sel(time_counter=(UKESMex['time_counter.season'] == 'JJA')).mean(dim = ['time_counter']).values)\n",
    "UKESMex_SON = (UKESMex.above95wt.sel(time_counter=(UKESMex['time_counter.season'] == 'SON')).mean(dim = ['time_counter']).values)\n",
    "\n",
    "ERA5ex_FY = (ERA5ex.above95wt.mean(dim = ['time_counter']).values)\n",
    "ERA5ex_DJF = (ERA5ex.above95wt.sel(time_counter=(ERA5ex['time_counter.season'] == 'DJF')).mean(dim = ['time_counter']).values)\n",
    "ERA5ex_MAM = (ERA5ex.above95wt.sel(time_counter=(ERA5ex['time_counter.season'] == 'MAM')).mean(dim = ['time_counter']).values)\n",
    "ERA5ex_JJA = (ERA5ex.above95wt.sel(time_counter=(ERA5ex['time_counter.season'] == 'JJA')).mean(dim = ['time_counter']).values)\n",
    "ERA5ex_SON = (ERA5ex.above95wt.sel(time_counter=(ERA5ex['time_counter.season'] == 'SON')).mean(dim = ['time_counter']).values)\n",
    "\n",
    "NCEPDOEex_FY = (NCEPDOEex.above95wt.mean(dim = ['time_counter']).values)\n",
    "NCEPDOEex_DJF = (NCEPDOEex.above95wt.sel(time_counter=(NCEPDOEex['time_counter.season'] == 'DJF')).mean(dim = ['time_counter']).values)\n",
    "NCEPDOEex_MAM = (NCEPDOEex.above95wt.sel(time_counter=(NCEPDOEex['time_counter.season'] == 'MAM')).mean(dim = ['time_counter']).values)\n",
    "NCEPDOEex_JJA = (NCEPDOEex.above95wt.sel(time_counter=(NCEPDOEex['time_counter.season'] == 'JJA')).mean(dim = ['time_counter']).values)\n",
    "NCEPDOEex_SON = (NCEPDOEex.above95wt.sel(time_counter=(NCEPDOEex['time_counter.season'] == 'SON')).mean(dim = ['time_counter']).values)\n",
    "\n",
    "NCEPNCARex_FY = (NCEPNCARex.above95wt.mean(dim = ['time_counter']).values)\n",
    "NCEPNCARex_DJF = (NCEPNCARex.above95wt.sel(time_counter=(NCEPNCARex['time_counter.season'] == 'DJF')).mean(dim = ['time_counter']).values)\n",
    "NCEPNCARex_MAM = (NCEPNCARex.above95wt.sel(time_counter=(NCEPNCARex['time_counter.season'] == 'MAM')).mean(dim = ['time_counter']).values)\n",
    "NCEPNCARex_JJA = (NCEPNCARex.above95wt.sel(time_counter=(NCEPNCARex['time_counter.season'] == 'JJA')).mean(dim = ['time_counter']).values)\n",
    "NCEPNCARex_SON = (NCEPNCARex.above95wt.sel(time_counter=(NCEPNCARex['time_counter.season'] == 'SON')).mean(dim = ['time_counter']).values)\n",
    "\n",
    "MERRAex_FY = (MERRAex.above95wt.mean(dim = ['time_counter']).values)\n",
    "MERRAex_DJF = (MERRAex.above95wt.sel(time_counter=(MERRAex['time_counter.season'] == 'DJF')).mean(dim = ['time_counter']).values)\n",
    "MERRAex_MAM = (MERRAex.above95wt.sel(time_counter=(MERRAex['time_counter.season'] == 'MAM')).mean(dim = ['time_counter']).values)\n",
    "MERRAex_JJA = (MERRAex.above95wt.sel(time_counter=(MERRAex['time_counter.season'] == 'JJA')).mean(dim = ['time_counter']).values)\n",
    "MERRAex_SON = (MERRAex.above95wt.sel(time_counter=(MERRAex['time_counter.season'] == 'SON')).mean(dim = ['time_counter']).values)\n",
    "\n",
    "JRAex_FY = (JRAex.above95wt.mean(dim = ['time_counter']).values)\n",
    "JRAex_DJF = (JRAex.above95wt.sel(time_counter=(JRAex['time_counter.season'] == 'DJF')).mean(dim = ['time_counter']).values)\n",
    "JRAex_MAM = (JRAex.above95wt.sel(time_counter=(JRAex['time_counter.season'] == 'MAM')).mean(dim = ['time_counter']).values)\n",
    "JRAex_JJA = (JRAex.above95wt.sel(time_counter=(JRAex['time_counter.season'] == 'JJA')).mean(dim = ['time_counter']).values)\n",
    "JRAex_SON = (JRAex.above95wt.sel(time_counter=(JRAex['time_counter.season'] == 'SON')).mean(dim = ['time_counter']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d181daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = False\n",
    "if ex:\n",
    "    data = np.zeros([5,6])\n",
    "    \n",
    "    data[0,0] = NCEPNCARex_FY\n",
    "    data[1,0] = NCEPNCARex_DJF\n",
    "    data[2,0] = NCEPNCARex_MAM\n",
    "    data[3,0] = NCEPNCARex_JJA\n",
    "    data[4,0] = NCEPNCARex_SON\n",
    "    \n",
    "    data[0,1] = NCEPDOEex_FY\n",
    "    data[1,1] = NCEPDOEex_DJF\n",
    "    data[2,1] = NCEPDOEex_MAM\n",
    "    data[3,1] = NCEPDOEex_JJA\n",
    "    data[4,1] = NCEPDOEex_SON\n",
    "    \n",
    "    data[0,2] = MERRAex_FY\n",
    "    data[1,2] = MERRAex_DJF\n",
    "    data[2,2] = MERRAex_MAM\n",
    "    data[3,2] = MERRAex_JJA\n",
    "    data[4,2] = MERRAex_SON\n",
    "\n",
    "    data[0,3] = JRAex_FY\n",
    "    data[1,3] = JRAex_DJF\n",
    "    data[2,3] = JRAex_MAM\n",
    "    data[3,3] = JRAex_JJA\n",
    "    data[4,3] = JRAex_SON\n",
    "    \n",
    "    data[0,4] = ERA5ex_FY\n",
    "    data[1,4] = ERA5ex_DJF\n",
    "    data[2,4] = ERA5ex_MAM\n",
    "    data[3,4] = ERA5ex_JJA\n",
    "    data[4,4] = ERA5ex_SON\n",
    "\n",
    "    data[0,5] = UKESMex_FY\n",
    "    data[1,5] = UKESMex_DJF\n",
    "    data[2,5] = UKESMex_MAM\n",
    "    data[3,5] = UKESMex_JJA\n",
    "    data[4,5] = UKESMex_SON \n",
    "\n",
    "\n",
    "    #n = ['ERA5','NCEP-NCAR','MERRA','NCEP-DOE','UKESM']\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                      index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "    df.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "    df.to_csv(f'./plts/allmod_weightabove95ex_windspeed_1980-2019_60-40S.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35da841",
   "metadata": {},
   "source": [
    "## print out the tables of means and extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44b72869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0  NCEP-NCAR   NCEP-DOE     MERRA     JRA3Q      ERA5     UKESM\n",
      "0  full year   9.002299  10.359714  8.797896  9.284363  9.051943  9.360448\n",
      "1        DJF   8.373870   9.617426  8.146661  8.643180  8.409101  8.743100\n",
      "2        MAM   9.106901  10.467496  8.825818  9.348591  9.127803  9.479588\n",
      "3        JJA   9.424096  10.860016  9.296988  9.734440  9.500867  9.706106\n",
      "4        SON   9.093366  10.481119  8.910957  9.400305  9.158935  9.513000\n",
      "\n",
      "  Unnamed: 0  NCEP-NCAR   NCEP-DOE      MERRA      JRA3Q       ERA5      UKESM\n",
      "0  full year  15.468449  18.546175  15.261471  16.200899  15.608290  15.941365\n",
      "1        DJF  14.567467  17.410640  14.294108  15.259261  14.748195  15.011784\n",
      "2        MAM  15.653359  18.747951  15.342449  16.330485  15.759609  16.056631\n",
      "3        JJA  16.108885  19.379755  16.042890  16.907042  16.232183  16.619869\n",
      "4        SON  15.527590  18.625617  15.348986  16.289861  15.677566  16.077177\n"
     ]
    }
   ],
   "source": [
    "w = pd.read_csv(f'./plts/allmod_mn_windspeed_1980-2019_60-40S.csv')\n",
    "print(w)\n",
    "print()\n",
    "w = pd.read_csv(f'./plts/allmod_weightabove95ex_windspeed_1980-2019_60-40S.csv')\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3da57",
   "metadata": {},
   "source": [
    "## trend function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b21ea4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_71636/1647863259.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpymannkendall\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgive_trends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/site-packages/pymannkendall/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpymannkendall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msens_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseasonal_sens_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhamed_rao_modification_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myue_wang_modification_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_whitening_modification_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend_free_pre_whitening_modification_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultivariate_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseasonal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregional_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelated_multivariate_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelated_seasonal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msens_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseasonal_sens_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhamed_rao_modification_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myue_wang_modification_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_whitening_modification_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend_free_pre_whitening_modification_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultivariate_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseasonal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregional_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelated_multivariate_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelated_seasonal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/site-packages/pymannkendall/pymannkendall.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    439\u001b[0m \"\"\"\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmeasurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m from scipy._lib._util import (check_random_state, MapWrapper,\n\u001b[1;32m     40\u001b[0m                               rng_integers, float_factorial)\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/site-packages/scipy/ndimage/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfourier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeasurements\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/swamp2/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import pymannkendall as mk\n",
    "from scipy import stats\n",
    "\n",
    "def give_trends(ts_y):\n",
    "\n",
    "    ts_x = np.arange(0,len(ts_y))\n",
    "    trend, h, mk_p, z, Tau, s, var_s, mk_slope, intercept = mk.original_test(ts_y)\n",
    "    lin_slope, intercept, r_value, lin_p, std_err = stats.linregress(ts_x,ts_y)\n",
    "    \n",
    "    return mk_slope, mk_p, lin_slope, lin_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50cbbc3",
   "metadata": {},
   "source": [
    "## Calculate trends in means (for table)\n",
    "\n",
    "get timeseries out plottingCode/extract_ts_2019.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "merra_ts = xr.open_dataset(f'{sdir}/MERRA_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "era_ts = xr.open_dataset(f'{sdir}/ERA5_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "doe_ts = xr.open_dataset(f'{sdir}/NCEP-DOE_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "ncar_ts = xr.open_dataset(f'{sdir}/NCEP-NCAR_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "ukesm_ts = xr.open_dataset(f'{sdir}/UKESM_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "jra_ts = xr.open_dataset(f'{sdir}/JRA_40-60S_mean_wspd_ts_1980-2019.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = ['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM']\n",
    "tdar = [ncar_ts, doe_ts, merra_ts, jra_ts, era_ts,   ukesm_ts]\n",
    "\n",
    "data = np.zeros([5,6])\n",
    "sig = np.zeros([5,6])\n",
    "for i in range(0,6):\n",
    "    print(dss[i])\n",
    "    ds = dss[i]\n",
    "    \n",
    "    tdat = tdar[i]\n",
    "    td = tdat\n",
    "    td = td.wspd10m.groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[0,i] = lin_slope* 10\n",
    "    sig[0,i] = lin_p\n",
    "    \n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'DJF')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[1,i] = lin_slope* 10\n",
    "    sig[1,i] = lin_p\n",
    "    \n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'MAM')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[2,i] = lin_slope* 10\n",
    "    sig[2,i] = lin_p\n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'JJA')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[3,i] = lin_slope* 10\n",
    "    sig[3,i] = lin_p\n",
    "    \n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'SON')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[4,i] = lin_slope * 10\n",
    "    sig[4,i] = lin_p\n",
    "    \n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                  index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "df2 = pd.DataFrame(sig, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                  index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "\n",
    "df.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "df.to_csv(f'./plts/mn_wspd_trend-1980-2019.csv')\n",
    "df2.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "df2.to_csv(f'./plts/mn_wspd_trendsig-1980-2019.csv')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = ['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM']\n",
    "tdar = [ncar_ts, doe_ts, merra_ts, jra_ts, era_ts,   ukesm_ts]\n",
    "\n",
    "data = np.zeros([5,6])\n",
    "sig = np.zeros([5,6])\n",
    "for i in range(0,6):\n",
    "    print(dss[i])\n",
    "    ds = dss[i]\n",
    "    \n",
    "    tdat = tdar[i]\n",
    "    td = tdat\n",
    "    td = td.wspd10m.groupby('time_counter.year').mean().values\n",
    "    print(len(td))\n",
    "    td = td[0:20]\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[0,i] = lin_slope* 10\n",
    "    sig[0,i] = lin_p\n",
    "    \n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'DJF')).\\\n",
    "    groupby('time_counter.year').mean().values[0:20]\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[1,i] = lin_slope* 10\n",
    "    sig[1,i] = lin_p\n",
    "    \n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'MAM')).\\\n",
    "    groupby('time_counter.year').mean().values[0:20]\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[2,i] = lin_slope* 10\n",
    "    sig[2,i] = lin_p\n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'JJA')).\\\n",
    "    groupby('time_counter.year').mean().values[0:20]\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[3,i] = lin_slope* 10\n",
    "    sig[3,i] = lin_p\n",
    "    \n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'SON')).\\\n",
    "    groupby('time_counter.year').mean().values[0:20]\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[4,i] = lin_slope * 10\n",
    "    sig[4,i] = lin_p\n",
    "    \n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                  index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "df2 = pd.DataFrame(sig, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                  index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "\n",
    "df.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "df.to_csv(f'./plts/mn_wspd_trend-1980-1999.csv')\n",
    "df2.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "df2.to_csv(f'./plts/mn_wspd_trendsig-1980-1999.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5638484",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pd.read_csv(f'./plts/mn_wspd_trendsig_1980-1999.csv', index_col=0)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb961eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a86dc",
   "metadata": {},
   "source": [
    "## Calculate trends in extremes (for table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7836105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_exlist(prod,yrst = 1980, yrend = 2019, \\\n",
    "                 baseDir = '/gpfs/data/greenocean2/software/products/windsFromComponents/dailyStandard/intProc/'):\n",
    "    yrs = np.arange(yrst,yrend+1,1)\n",
    "    ylist = []\n",
    "    for i in range(0,len(yrs)):\n",
    "        ty = f'{baseDir}/{prod}_windex_{yrs[i]}.nc'\n",
    "        t2 = glob.glob(ty)\n",
    "        #print(t2)\n",
    "        ylist.append(t2[0])\n",
    "    return ylist\n",
    "\n",
    "MERRAex = xr.open_mfdataset(make_exlist('MERRA'))\n",
    "ERA5ex = xr.open_mfdataset(make_exlist('ERA5'))\n",
    "NCEPDOEex = xr.open_mfdataset(make_exlist('NCEP-DOE'))\n",
    "NCEPNCARex = xr.open_mfdataset(make_exlist('NCEP-NCAR'))\n",
    "UKESMex = xr.open_mfdataset(make_exlist('UKESM'))\n",
    "JRAex = xr.open_mfdataset(make_exlist('JRA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = ['NCEP-NCAR','NCEP-DOE','MERRA','JRA','ERA5','UKESM']\n",
    "tdar = [NCEPNCARex, NCEPDOEex,  MERRAex, JRAex, ERA5ex, UKESMex,]\n",
    "\n",
    "data = np.zeros([5,6])\n",
    "sig = np.zeros([5,6])\n",
    "for i in range(0,6):\n",
    "    print(dss[i])\n",
    "    ds = dss[i]\n",
    "    \n",
    "    tdat = tdar[i]\n",
    "    td = tdat\n",
    "    td = td.above95wt.groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[0,i] = lin_slope* 10\n",
    "    sig[0,i] = lin_p\n",
    "    \n",
    "\n",
    "    td = tdat\n",
    "    td = td.above95wt.sel(time_counter=(td['time_counter.season'] == 'DJF')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[1,i] = lin_slope* 10\n",
    "    sig[1,i] = lin_p\n",
    "    \n",
    "\n",
    "    td = tdat\n",
    "    td = td.above95wt.sel(time_counter=(td['time_counter.season'] == 'MAM')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[2,i] = lin_slope* 10\n",
    "    sig[2,i] = lin_p\n",
    "\n",
    "    td = tdat\n",
    "    td = td.above95wt.sel(time_counter=(td['time_counter.season'] == 'JJA')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[3,i] = lin_slope* 10\n",
    "    sig[3,i] = lin_p\n",
    "    \n",
    "    td = tdat\n",
    "    td = td.above95wt.sel(time_counter=(td['time_counter.season'] == 'SON')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[4,i] = lin_slope * 10\n",
    "    sig[4,i] = lin_p\n",
    "    \n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                  index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "df2 = pd.DataFrame(sig, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                  index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "\n",
    "df.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "df.to_csv(f'./plts/ex_wspd_trend.csv')\n",
    "df2.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "df2.to_csv(f'./plts/ex_wspd_trendsig.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab5b40",
   "metadata": {},
   "source": [
    "## ok, what tables did we make?\n",
    "\n",
    "    df.to_csv(f'./plts/allmod_mn_windspeed_1980-2019_60-40S.csv')\n",
    "    df.to_csv(f'./plts/allmod_weightabove95ex_windspeed_1980-2019_60-40S.csv')\n",
    "    df.to_csv(f'./plts/mn_wspd_trend.csv')\n",
    "    df2.to_csv(f'./plts/mn_wspd_trendsig.csv')\n",
    "    df.to_csv(f'./plts/ex_wspd_trend.csv')\n",
    "    df2.to_csv(f'./plts/ex_wspd_trendsig.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c14ae3",
   "metadata": {},
   "source": [
    "## FIG-MEAN-EX CODE visualize timeseries of trends/extremes\n",
    "\n",
    "- means timeseries made in extract_ts.py or extract_ts_2019.py  which needs to be run in the pyxr env, which has a good xarray\n",
    "\n",
    "- trends calculated in windEval/plottingCode/trend_table.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pd.read_csv('./plts/mn_wspd_trend.csv')\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import coldic as cd\n",
    "# reload(cd)\n",
    "\n",
    "# ncar_ts = xr.open_dataset(f'{sdir}NCEP-NCAR_40-60S_mean_wspd_ts.nc')\n",
    "# doe_ts = xr.open_dataset(f'{sdir}NCEP-DOE_40-60S_mean_wspd_ts.nc')\n",
    "# ukesm_ts = xr.open_dataset(f'{sdir}UKESM_40-60S_mean_wspd_ts.nc')\n",
    "# era_ts = xr.open_dataset(f'{sdir}ERA5_40-60S_mean_wspd_ts.nc')\n",
    "# jra_ts = xr.open_dataset(f'{sdir}JRA_40-60S_mean_wspd_ts.nc')\n",
    "# merra_ts = xr.open_dataset(f'{sdir}MERRA_40-60S_mean_wspd_ts.nc')\n",
    "\n",
    "\n",
    "# tn = ['ERA5','NCEP-NCAR','MERRA','NCEP-DOE','UKESM']\n",
    "# tnt = ['ERA5','NCEP-NCAR','MERRA-2','NCEP-DOE II','UKESM1']\n",
    "# tdar = [era_ts, ncar_ts, merra_ts, doe_ts,  ukesm_ts]\n",
    "# tdarx = [ERA5ex, NCEPNCARex, MERRAex, NCEPDOEex, UKESMex]\n",
    "\n",
    "# fact = 0.9\n",
    "# fig, axs = plt.subplots(3,2, figsize=(12*fact, 9*fact), facecolor='w', edgecolor='k')\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i in range(0,5):\n",
    "    \n",
    "#     xmi = 8; mar = 5.3\n",
    "#     td = tdar[i]\n",
    "#     a = td.groupby('time_counter.year').mean()\n",
    "#     axs[0].plot(a.year,a.wspd10m, color = cd.prod[tn[i]]['col'], \\\n",
    "#                 label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'])\n",
    "#     axs[0].set_ylim([xmi,xmi+mar])\n",
    "    \n",
    "#     xmi = 7.5\n",
    "#     a = td.sel(time_counter=(td['time_counter.season'] == 'DJF')).groupby('time_counter.year').mean()\n",
    "#     axs[2].plot(a.year,a.wspd10m, color = cd.prod[tn[i]]['col'], \\\n",
    "#                 label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'])\n",
    "#     axs[2].set_ylim([xmi,xmi+mar])\n",
    "\n",
    "#     xmi = 8.5\n",
    "#     a = td.sel(time_counter=(td['time_counter.season'] == 'JJA')).groupby('time_counter.year').mean()\n",
    "#     axs[4].plot(a.year,a.wspd10m, color = cd.prod[tn[i]]['col'], \\\n",
    "#                 label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'])\n",
    "#     axs[4].set_ylim([xmi,xmi+mar])\n",
    "    \n",
    "    \n",
    "# for i in range(0,6):\n",
    "#     axs[i].set_xlim([1980,2020])\n",
    "#     axs[0].legend(ncol = 3, fontsize = 10, loc = 'best')\n",
    "    \n",
    "    \n",
    "# for i in range(0,5):\n",
    "    \n",
    "#     xmi = 14.5; \n",
    "#     td = tdarx[i]\n",
    "#     a = td.groupby('time_counter.year').mean()\n",
    "#     axs[1].plot(a.year,a.above95wt, color = cd.prod[tn[i]]['col'], \\\n",
    "#                 label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'])\n",
    "#     axs[1].set_ylim([xmi,xmi+mar])\n",
    "    \n",
    "#     xmi = 13.5;\n",
    "#     a = td.sel(time_counter=(td['time_counter.season'] == 'DJF')).groupby('time_counter.year').mean()\n",
    "#     axs[3].plot(a.year,a.above95wt, color = cd.prod[tn[i]]['col'], \\\n",
    "#                 label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'])\n",
    "#     axs[3].set_ylim([xmi,xmi+mar])\n",
    "\n",
    "#     xmi = 15;\n",
    "#     a = td.sel(time_counter=(td['time_counter.season'] == 'JJA')).groupby('time_counter.year').mean()\n",
    "#     axs[5].plot(a.year,a.above95wt, color = cd.prod[tn[i]]['col'], \\\n",
    "#                 label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'])\n",
    "#     axs[5].set_ylim([xmi,xmi+mar])\n",
    "    \n",
    "# tits = ['mean wind speed, full year', 'extreme wind speed, full year',\\\n",
    "#         'mean wind speed, DJF', 'extreme wind speed, DJF',\n",
    "#         'mean wind speed, JJA', 'extreme wind speed, JJA',]\n",
    "# for i in range(0,6):\n",
    "#     axs[i].set_xlim([1980,2020])\n",
    "#     axs[0].legend(ncol = 2, fontsize = 12, loc = 'best')\n",
    "#     axs[i].set_ylabel('m s$^{-1}$')\n",
    "#     axs[i].set_title(tits[i])\n",
    "    \n",
    "# plt.tight_layout()\n",
    "\n",
    "# #fig.savefig('./plts/Fig-mean-extreme.jpg', dpi = 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edd87dc1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f5c61af",
   "metadata": {},
   "source": [
    "## gaussian KDE \n",
    "\n",
    "this got put into getKDE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = False\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "if ex:\n",
    "\n",
    "    def custhist(tdat, nbins, start, end, tweights = None):\n",
    "        #bins = 25\n",
    "        hist_met_vflx, bins = np.histogram(np.ravel(tdat), bins=nbins,\\\n",
    "                                     range = [start, end], weights=tweights)\n",
    "\n",
    "        bin_cent = bins + (bins[1]-bins[0])/2\n",
    "        tot_count = np.sum(hist_met_vflx)\n",
    "\n",
    "\n",
    "        binsback = bins\n",
    "        bin_cent = bin_cent[0:nbins]\n",
    "        histback = hist_met_vflx/tot_count\n",
    "\n",
    "        return binsback, bin_cent, histback\n",
    "\n",
    "    def make_yearlist_prod(yrst, yrend, prod = 'ERA5'):\n",
    "\n",
    "        baseDir = '/gpfs/data/greenocean2/software/products/windsFromComponents/dailyStandard/'\n",
    "\n",
    "        yrs = np.arange(yrst,yrend+1,1)\n",
    "        ylist = []\n",
    "        for i in range(0,len(yrs)):\n",
    "            ty = f'{baseDir}/{prod}/{prod}_wind_daily_1x1_{yrs[i]}.nc'\n",
    "            t2 = glob.glob(ty)\n",
    "            #print(t2)\n",
    "            ylist.append(t2[0])\n",
    "        return ylist\n",
    "\n",
    "    def get_gaussian_kde(prod = 'ERA5', seas = 'FY', yst = 1940, yen = 1949, xmi = 0, xma = 25):\n",
    "\n",
    "        tdir = '/gpfs/data/greenocean2/software/products/windsFromComponents/dailyStandard/intProc/'\n",
    "        savenam = f'KDE-{prod}-{seas}-{yst}-{yen}.nc'#seas\n",
    "        print(savenam)\n",
    "\n",
    "        yl = make_yearlist_prod(yst, yen, prod)\n",
    "        td = xr.open_mfdataset(yl)\n",
    "\n",
    "        if seas == 'FY':\n",
    "            q = td.wspd10m.isel(lat = slice(30,50))\n",
    "            masksiz = (len(q.time_counter))\n",
    "\n",
    "        else:\n",
    "            q = td.wspd10m.sel(time_counter=(td['time_counter.season'] == seas)).isel(lat = slice(30,50))\n",
    "            masksiz = (len(q.time_counter))\n",
    "            print(masksiz)\n",
    "\n",
    "        tval = q.values\n",
    "\n",
    "        cdomask = xr.open_dataset('/gpfs/home/mep22dku/scratch/SOZONE/windAnalyis/wspdComponents/PlankTOMmask_krg.nc')\n",
    "        tmask = cdomask.aream2.mean(dim = 'time_counter').isel(lat = slice(30,50)).values\n",
    "\n",
    "        y = (np.shape(tmask)[0])\n",
    "        x = (np.shape(tmask)[1])\n",
    "        timask = np.zeros([masksiz,y,x])\n",
    "        for i in range(0,masksiz):\n",
    "            timask[i,:,:] = tmask\n",
    "\n",
    "        kde_x = np.linspace(xmi, xma, 100)\n",
    "        kde = gaussian_kde(np.ravel(tval), weights=np.ravel(timask))\n",
    "        kde_val = kde(kde_x)\n",
    "\n",
    "        binsback, bin_cent, histback, = custhist(np.ravel(tval), 100, xmi, xma, tweights = np.ravel(timask))\n",
    "\n",
    "\n",
    "        data_vars = {'kde':(['kde_x'],kde_val),\n",
    "                            'hist':(['hist_x'],histback),\n",
    "        }\n",
    "        # define coordinates\n",
    "        coords = {'kde_x': (['kde_x'], kde_x),\n",
    "                  'hist_x': (['hist_x'], bin_cent),\n",
    "\n",
    "                 }\n",
    "        # define global attributes\n",
    "        attrs = {'made in':'SOZONE/MEDUSA/makeYearlyMEDUSAsubsetfiles.ipynb',\n",
    "        'desc': 'yearly medusa files, saving only variables of interest'\n",
    "        }\n",
    "        ds = xr.Dataset(data_vars=data_vars,\n",
    "        coords=coords,\n",
    "        attrs=attrs)\n",
    "        ds.to_netcdf(f'{tdir}{savenam}')\n",
    "\n",
    "        return \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    prods = ['UKESM','ERA5','NCEP-DOE','NCEP-NCAR','MERRA']\n",
    "    prods = ['JRA']#UKESM','ERA5','NCEP-DOE','NCEP-NCAR','MERRA']\n",
    "    yrs = [1980]\n",
    "    seass = ['FY','DJF']#,'JJA',]\n",
    "\n",
    "    for prod in prods:\n",
    "        for yr in yrs:\n",
    "            for s in seass:\n",
    "                print(s)\n",
    "                yre = yr+39\n",
    "                get_gaussian_kde(prod, seas = s, yst = yr, yen = yre, xmi = 0, xma = 20)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a588e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(timeseries, n = 3):\n",
    "    # Ensure n is valid and doesn't exceed the length of the timeseries\n",
    "    if n <= 0 or n > len(timeseries):\n",
    "        raise ValueError(\"Window size n must be between 1 and the length of the timeseries.\")\n",
    "    \n",
    "    # Compute the n-point moving average\n",
    "    return np.convolve(timeseries, np.ones(n) / n, mode='valid')\n",
    "\n",
    "# Example usage:\n",
    "timeseries = [10, 20, 30, 40, 50, 60, 70]\n",
    "n = 3  # Adjust the window size here\n",
    "filtered_timeseries = moving_average(timeseries, n)\n",
    "print(filtered_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7900ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdir = '/gpfs/data/greenocean2/software/products/windsFromComponents/dailyStandard/intProc/'\n",
    "import coldic as cd\n",
    "reload(cd)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "fact = 1\n",
    "fig = plt.figure(figsize=(12*fact, 10*fact))\n",
    "gs = fig.add_gridspec(3, 4)\n",
    "ax1 = fig.add_subplot(gs[0, 0:2])\n",
    "ax2 = fig.add_subplot(gs[0, 2:4])\n",
    "ax3 = fig.add_subplot(gs[1, 0:2])\n",
    "ax4 = fig.add_subplot(gs[1, 2:4])\n",
    "ax5 = fig.add_subplot(gs[2, 0:1])\n",
    "ax6 = fig.add_subplot(gs[2, 1:2])\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "ax8 = fig.add_subplot(gs[2, 3])\n",
    "\n",
    "ax1.set_title('mean wind speed trend \\n relative to climatology, full year')\n",
    "ax2.set_title('mean wind speed trend  relative to climatology, DJF')\n",
    "ax3.set_title('wind distribution, full year')\n",
    "ax4.set_title('wind distribution, DJF')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "### KDEs\n",
    "\n",
    "prods = ['NCEP-NCAR','MERRA','JRA','ERA5','UKESM',]\n",
    "ls = [':','-']\n",
    "\n",
    "al = 0.1\n",
    "\n",
    "\n",
    "for p in prods:\n",
    "    ls = '-'\n",
    "    if p == 'UKESM':\n",
    "        ls = ':'\n",
    "    w = xr.open_dataset(f'{tdir}/KDE-{p}-FY-1980-2019.nc')\n",
    "    ax3.plot(w.kde_x, w.kde, color = cd.prod[p]['col'], linewidth = 2, linestyle = ls, label = cd.prod[p]['fnam'])\n",
    "    ax3.fill_between(w.kde_x, np.zeros_like(w.kde_x.values), w.kde.values, \\\n",
    "                        color = cd.prod[p]['col'], alpha = al, zorder = 20)    \n",
    "    \n",
    "    w = xr.open_dataset(f'{tdir}/KDE-{p}-DJF-1980-2019.nc')\n",
    "    ax4.plot(w.kde_x, w.kde, color = cd.prod[p]['col'], linewidth = 2, linestyle = ls)\n",
    "    ax4.fill_between(w.kde_x, np.zeros_like(w.kde_x.values), w.kde.values, \\\n",
    "                        color = cd.prod[p]['col'], alpha = al, zorder = 20)        \n",
    "    \n",
    "    \n",
    "# Create an inset inside ax3\n",
    "ia3 = inset_axes(ax3, width=\"32%\", height=\"40%\", loc=\"upper right\")  # width and height are relative to ax3\n",
    "ia4 = inset_axes(ax4, width=\"32%\", height=\"40%\", loc=\"upper right\")\n",
    "\n",
    "for p in prods:\n",
    "    ls = '-'\n",
    "    if p == 'UKESM':\n",
    "        ls = ':'\n",
    "    w = xr.open_dataset(f'{tdir}/KDE-{p}-FY-1980-2019.nc')\n",
    "    ia3.plot(w.kde_x, w.kde, color = cd.prod[p]['col'], linewidth = 2, linestyle = ls, label = cd.prod[p]['fnam'])\n",
    "    ia3.fill_between(w.kde_x, np.zeros_like(w.kde_x.values), w.kde.values, \\\n",
    "                        color = cd.prod[p]['col'], alpha = al, zorder = 20)    \n",
    "    \n",
    "    w = xr.open_dataset(f'{tdir}/KDE-{p}-DJF-1980-2019.nc')\n",
    "    ia4.plot(w.kde_x, w.kde, color = cd.prod[p]['col'], linewidth = 2, linestyle = ls)\n",
    "    ia4.fill_between(w.kde_x, np.zeros_like(w.kde_x.values), w.kde.values, \\\n",
    "                        color = cd.prod[p]['col'], alpha = al, zorder = 20)     \n",
    "\n",
    "    ia3.set_xlim([15,21])\n",
    "    ia3.set_ylim([0,0.038])\n",
    "\n",
    "    ia4.set_xlim([15,21])\n",
    "    ia4.set_ylim([0,0.038])\n",
    "\n",
    "\n",
    "\n",
    "# for p in prods:\n",
    "#     ls = '-'\n",
    "#     if p == 'UKESM':\n",
    "#         ls = ':'\n",
    "#     w = xr.open_dataset(f'{tdir}/KDE-{p}-FY-1980-2019.nc')\n",
    "#     ax3.plot(w.kde_x, w.kde, color = cd.prod[p]['col'], linewidth = 2, linestyle = ls, label = cd.prod[p]['fnam'])\n",
    "#     ax3.fill_between(w.kde_x, np.zeros_like(w.kde_x.values), w.kde.values, \\\n",
    "#                         color = cd.prod[p]['col'], alpha = al, zorder = 20)    \n",
    "    \n",
    "#     w = xr.open_dataset(f'{tdir}/KDE-{p}-DJF-1980-2019.nc')\n",
    "#     ax4.plot(w.kde_x, w.kde, color = cd.prod[p]['col'], linewidth = 2, linestyle = ls)\n",
    "#     ax4.fill_between(w.kde_x, np.zeros_like(w.kde_x.values), w.kde.values, \\\n",
    "#                         color = cd.prod[p]['col'], alpha = al, zorder = 20)        \n",
    "\n",
    "# ax3.legend(loc = 'best')\n",
    "\n",
    "merra_ts = xr.open_dataset(f'{sdir}/MERRA_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "era_ts = xr.open_dataset(f'{sdir}/ERA5_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "doe_ts = xr.open_dataset(f'{sdir}/NCEP-DOE_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "ncar_ts = xr.open_dataset(f'{sdir}/NCEP-NCAR_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "jra_ts = xr.open_dataset(f'{sdir}/JRA_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "ukesm_ts = xr.open_dataset(f'{sdir}/UKESM_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "\n",
    "tn = ['NCEP-NCAR','MERRA','JRA','ERA5','UKESM']\n",
    "tnt = ['NCEP-NCAR','MERRA-2','JRA3Q','ERA5','UKESM']\n",
    "tdar = [ ncar_ts,merra_ts, jra_ts, era_ts, ukesm_ts]\n",
    "\n",
    "tdarx = [NCEPNCARex, MERRAex, JRAex, ERA5ex, UKESMex]\n",
    "\n",
    "for i in range(0,5):\n",
    "    \n",
    "    xmi = 8.25; mar = 2.75\n",
    "    td = tdar[i]\n",
    "    a = td.groupby('time_counter.year').mean()\n",
    "    ts = a.wspd10m - a.wspd10m.mean()\n",
    "    tsv = ts.values\n",
    "    ax1.plot(a.year,tsv, color = cd.prod[tn[i]]['col'], \\\n",
    "             linestyle = cd.prod[tn[i]]['linestyle'], linewidth = 0.5)\n",
    "    \n",
    "    ax1.plot(a.year[1:-1],moving_average(tsv), color = cd.prod[tn[i]]['col'], \\\n",
    "                label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'], linewidth = 1.5)\n",
    "        \n",
    "    #ax1.set_ylim([xmi,xmi+mar])\n",
    "    \n",
    "    xmi = 7.5\n",
    "    a = td.sel(time_counter=(td['time_counter.season'] == 'DJF')).groupby('time_counter.year').mean()\n",
    "    ts = a.wspd10m - a.wspd10m.mean()\n",
    "    tsv = ts.values\n",
    "    ax2.plot(a.year,tsv, color = cd.prod[tn[i]]['col'], \\\n",
    "                label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'], linewidth = 0.5)\n",
    "    \n",
    "    ax2.plot(a.year[1:-1],moving_average(tsv), color = cd.prod[tn[i]]['col'], \\\n",
    "                label = cd.prod[tn[i]]['fnam'], linestyle = cd.prod[tn[i]]['linestyle'], linewidth = 1.5)\n",
    "    #ax2.set_ylim([xmi,xmi+mar])\n",
    "    ax2.set_xlim([1980,2020])\n",
    "    ax1.set_xlim([1980,2020])\n",
    "    ax1.legend(loc = 'best', ncol = 2, fontsize = 10)\n",
    "    ax1.axhline(y=0)\n",
    "    ax2.axhline(y=0)\n",
    "    ax1.set_ylim([-0.6,0.6])\n",
    "    ax2.set_ylim([-0.6,0.6])\n",
    "    \n",
    "\n",
    "\n",
    "### mean wind speed fy\n",
    "for i in range(0,5):\n",
    "\n",
    "    td = tdar[i]\n",
    "    a = td.wspd10m.groupby('time_counter.year').mean().values[0:20]\n",
    "    wym = np.mean(a)\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(a)\n",
    "    print(f'{tn[i]} FY 1980-1999 {wym}, {lin_slope}, {lin_p}')\n",
    "    alph = 1\n",
    "    SW = False\n",
    "    if lin_p > 0.05:\n",
    "        print(f'{tn[i]} SIGNIFICANCE WARNING')\n",
    "        SW = True\n",
    "        \n",
    "    mkz = 'o'; ms = 10\n",
    "    if tn[i] == 'UKESM': mkz = 's'; ms = 10\n",
    "    ax5.plot(wym, lin_slope*10, color ='w', \\\n",
    "             marker = mkz, markersize = ms, markeredgecolor = cd.prod[tn[i]]['col'], alpha = alph)     \n",
    "    if SW:\n",
    "        ax5.plot(wym, lin_slope*10, color ='grey', \\\n",
    "             marker = 'x', markersize = ms+5)  \n",
    "    \n",
    "    a = td.wspd10m.groupby('time_counter.year').mean().values\n",
    "    wym = np.mean(a)\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(a)\n",
    "    print(f'{tn[i]} FY 1980-2019 {wym}, {lin_slope}, {lin_p}')\n",
    "    alph = 1\n",
    "    SW = False\n",
    "    if lin_p > 0.05:\n",
    "        print(f'{tn[i]} SIGNIFICANCE WARNING')\n",
    "        SW = True\n",
    "\n",
    "        \n",
    "    mkz = 'o'; ms = 10\n",
    "    if tn[i] == 'UKESM': mkz = 's'; ms = 10\n",
    "    ax5.plot(wym, lin_slope*10, color =cd.prod[tn[i]]['col'], \\\n",
    "             marker = mkz, markersize = ms, markeredgecolor = cd.prod[tn[i]]['col'], alpha = alph)    \n",
    "    if SW:\n",
    "        ax5.plot(wym, lin_slope*10, color ='grey', \\\n",
    "             marker = 'x', markersize = ms+5)  \n",
    "    \n",
    "    #### extreme\n",
    "    td = tdarx[i]\n",
    "    a = td.above95wt.groupby('time_counter.year').mean().values[0:20]\n",
    "    wym = np.mean(a)\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(a)\n",
    "    print(f'{tn[i]}  FY 1980-1999 (extremes) {wym}, {lin_slope}, {lin_p}')\n",
    "    alph = 1\n",
    "    SW = False\n",
    "    if lin_p > 0.05:\n",
    "        print(f'{tn[i]} SIGNIFICANCE WARNING')\n",
    "        SW = True\n",
    "        \n",
    "    mkz = 'o'; ms = 10\n",
    "    if tn[i] == 'UKESM': mkz = 's'; ms = 10\n",
    "    ax6.plot(wym, lin_slope*10, color ='w', \\\n",
    "             marker = mkz, markersize = ms, markeredgecolor = cd.prod[tn[i]]['col'], alpha = alph)    \n",
    "    if SW:\n",
    "        ax6.plot(wym, lin_slope*10, color ='grey', \\\n",
    "             marker = 'x', markersize = ms+5)  \n",
    "    \n",
    "    a = td.above95wt.groupby('time_counter.year').mean().values\n",
    "    wym = np.mean(a)\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(a)\n",
    "    print(f'{tn[i]}  FY 1980-2019 (extremes)  {wym}, {lin_slope}, {lin_p}')\n",
    "    alph = 1\n",
    "    SW = False\n",
    "    if lin_p > 0.05:\n",
    "        print(f'{tn[i]} SIGNIFICANCE WARNING')\n",
    "        SW = True\n",
    "\n",
    "    \n",
    "    mkz = 'o'; ms = 10\n",
    "    if tn[i] == 'UKESM': mkz = 's'; ms = 10\n",
    "    ax6.plot(wym, lin_slope*10, color =cd.prod[tn[i]]['col'], \\\n",
    "             marker = mkz, markersize = ms, markeredgecolor = cd.prod[tn[i]]['col'], alpha = alph)     \n",
    "    if SW:\n",
    "        ax6.plot(wym, lin_slope*10, color ='grey', \\\n",
    "             marker = 'x', markersize = ms+5)      \n",
    "    \n",
    "    \n",
    "### mean wind speed fy\n",
    "for i in range(0,5):\n",
    "\n",
    "    td = tdar[i]\n",
    "    a = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'DJF')).groupby('time_counter.year').mean().values[0:20]\n",
    "    wym = np.mean(a)\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(a)\n",
    "    print(f'{tn[i]} DJF 1980-1999 {wym}, {lin_slope}, {lin_p}')\n",
    "    alph = 1\n",
    "    SW = False\n",
    "    if lin_p > 0.05:\n",
    "        print(f'{tn[i]} SIGNIFICANCE WARNING')\n",
    "        SW = True\n",
    "    \n",
    "    mkz = 'o'; ms = 10\n",
    "    if tn[i] == 'UKESM': mkz = 's'; ms = 10\n",
    "    ax7.plot(wym, lin_slope*10, color ='w', \\\n",
    "             marker = mkz, markersize = ms, markeredgecolor = cd.prod[tn[i]]['col'], alpha = alph)     \n",
    "    if SW:\n",
    "        ax7.plot(wym, lin_slope*10, color ='grey', \\\n",
    "             marker = 'x', markersize = ms+5)  \n",
    "    \n",
    "    a = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'DJF')).groupby('time_counter.year').mean().values\n",
    "    wym = np.mean(a)\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(a)\n",
    "    print(f'{tn[i]} DJF 1980-2019 {wym}, {lin_slope}, {lin_p}')\n",
    "    alph = 1\n",
    "    SW = False\n",
    "    if lin_p > 0.05:\n",
    "        print(f'{tn[i]} SIGNIFICANCE WARNING')\n",
    "        SW = True\n",
    "\n",
    "        \n",
    "    mkz = 'o'; ms = 10\n",
    "    if tn[i] == 'UKESM': mkz = 's'; ms = 10\n",
    "    ax7.plot(wym, lin_slope*10, color =cd.prod[tn[i]]['col'], \\\n",
    "             marker = mkz, markersize = ms, markeredgecolor = cd.prod[tn[i]]['col'], alpha = alph)    \n",
    "    if SW:\n",
    "        ax7.plot(wym, lin_slope*10, color ='grey', \\\n",
    "             marker = 'x', markersize = ms+5)  \n",
    "    \n",
    "    #### extreme\n",
    "    td = tdarx[i]\n",
    "    a = td.above95wt.sel(time_counter=(td['time_counter.season'] == 'DJF')).groupby('time_counter.year').mean().values[0:20]\n",
    "    wym = np.mean(a)\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(a)\n",
    "    print(f'{tn[i]} DJF 1980-1999 (extremes) {wym}, {lin_slope}, {lin_p}')\n",
    "    alph = 1\n",
    "    SW = False\n",
    "    if lin_p > 0.05:\n",
    "        print(f'{tn[i]} SIGNIFICANCE WARNING')\n",
    "        SW = True\n",
    "        \n",
    "    mkz = 'o'; ms = 10\n",
    "    if tn[i] == 'UKESM': mkz = 's'; ms = 10\n",
    "    ax8.plot(wym, lin_slope*10, color ='w', \\\n",
    "             marker = mkz, markersize = ms, markeredgecolor = cd.prod[tn[i]]['col'], alpha = alph)    \n",
    "    if SW:\n",
    "        ax8.plot(wym, lin_slope*10, color ='grey', \\\n",
    "             marker = 'x', markersize = ms+5)  \n",
    "\n",
    "    a = td.above95wt.sel(time_counter=(td['time_counter.season'] == 'DJF')).groupby('time_counter.year').mean().values\n",
    "    wym = np.mean(a)\n",
    "    mk_slope, mk_p, lin_slope, lin_p = give_trends(a)\n",
    "    print(f'{tn[i]} DJF 1980-2019 (extremes) {wym}, {lin_slope}, {lin_p}')\n",
    "    alph = 1\n",
    "    SW = False\n",
    "    if lin_p > 0.05:\n",
    "        print(f'{tn[i]} SIGNIFICANCE WARNING')\n",
    "        SW = True\n",
    "        \n",
    "    mkz = 'o'; ms = 10\n",
    "    if tn[i] == 'UKESM': mkz = 's'; ms = 10\n",
    "    ax8.plot(wym, lin_slope*10, color =cd.prod[tn[i]]['col'], \\\n",
    "             marker = mkz, markersize = ms, markeredgecolor = cd.prod[tn[i]]['col'], alpha = alph)    \n",
    "    if SW:\n",
    "        ax8.plot(wym, lin_slope*10, color ='grey', \\\n",
    "             marker = 'x', markersize = ms+5)    \n",
    "\n",
    "    \n",
    "    ax5.set_ylim([-0.05,0.56])\n",
    "    ax6.set_ylim([-0.05,0.56])\n",
    "    ax7.set_ylim([-0.05,0.56])\n",
    "    ax8.set_ylim([-0.05,0.56])\n",
    "    \n",
    "    of = 1.38\n",
    "    ax5.set_xlim([8.5,8.5+of])\n",
    "    ax6.set_xlim([15,15+of])\n",
    "    ax7.set_xlim([7.8,7.8+of])\n",
    "    ax8.set_xlim([14,14+of])\n",
    "    \n",
    "    ### \n",
    "    ax1.set_xlim([1980,2019])\n",
    "    ax2.set_xlim([1980,2019])\n",
    "    ax1.set_ylabel('m s$^{-1}$')\n",
    "    ax2.set_ylabel('m s$^{-1}$')\n",
    "    ax3.set_ylim([0,0.13])\n",
    "    ax4.set_ylim([0,0.13])\n",
    "    ax3.set_xlim([0,24])\n",
    "    ax4.set_xlim([0,24])   \n",
    "    \n",
    "    axs = [ax1, ax2, ax3, ax4, ax5, ax6, ax6, ax7, ax8, ia3, ia4]\n",
    "    for ax in axs:\n",
    "        ax.grid(linestyle = ':', color = 'grey', alpha = 0.8)\n",
    "    \n",
    "    axs = [ax3, ax4, ax5, ax6, ax6, ax7, ax8]\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('m s$^{-1}$') \n",
    "    axs = [ax5, ax6, ax6, ax7, ax8]\n",
    "    for ax in axs:\n",
    "        ax.set_ylabel('m s$^{-1}$ decade$^{-1}$') \n",
    "        \n",
    "    ax5.set_title('trend vs. mean \\n (mean winds, full year)')\n",
    "    ax6.set_title('trend vs. mean \\n (extreme winds, full year)')\n",
    "    ax7.set_title('trend vs. mean \\n (mean winds, DJF)')\n",
    "    ax8.set_title('trend vs. mean \\n (extreme winds, DJF)')\n",
    "    #above95wt\n",
    "    #above95wt\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.savefig('./plts/Fig-mean-extreme.jpg', dpi = 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c1d05-2167-4e60-9831-66644735cccb",
   "metadata": {},
   "source": [
    "# IAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2612b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCEP-NCAR\n",
      "0.217999370477673\n",
      "NCEP-DOE\n",
      "0.2765281476665015\n",
      "MERRA\n",
      "0.15796505083815376\n",
      "JRA3Q\n",
      "0.10460371851262593\n",
      "ERA5\n",
      "0.1069408240942777\n",
      "UKESM\n",
      "0.09888093720233063\n",
      "           NCEP-NCAR  NCEP-DOE     MERRA     JRA3Q      ERA5     UKESM\n",
      "full year   2.421584  2.669251  1.795481  1.126662  1.181409  1.056370\n",
      "DJF         3.054685  3.099408  2.203538  1.581987  1.668828  1.451707\n",
      "MAM         2.737487  3.103465  2.227737  1.415912  1.348500  1.451798\n",
      "JJA         2.686941  2.964191  2.197969  1.686346  1.719746  1.500227\n",
      "SON         2.836364  3.022472  2.072205  1.758973  1.944595  1.804273\n"
     ]
    }
   ],
   "source": [
    "merra_ts = xr.open_dataset(f'{sdir}/MERRA_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "era_ts = xr.open_dataset(f'{sdir}/ERA5_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "doe_ts = xr.open_dataset(f'{sdir}/NCEP-DOE_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "ncar_ts = xr.open_dataset(f'{sdir}/NCEP-NCAR_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "ukesm_ts = xr.open_dataset(f'{sdir}/UKESM_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "jra_ts = xr.open_dataset(f'{sdir}/JRA_40-60S_mean_wspd_ts_1980-2019.nc')\n",
    "\n",
    "dss = ['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM']\n",
    "tdar = [ncar_ts, doe_ts, merra_ts, jra_ts, era_ts,   ukesm_ts]\n",
    "\n",
    "data = np.zeros([5,6])\n",
    "sig = np.zeros([5,6])\n",
    "for i in range(0,6):\n",
    "    print(dss[i])\n",
    "    ds = dss[i]\n",
    "    \n",
    "    tdat = tdar[i]\n",
    "    td = tdat\n",
    "    td = td.wspd10m.groupby('time_counter.year').mean().values\n",
    "    #print(td)\n",
    "    w = np.std(td)\n",
    "    print(w)\n",
    "    m = np.mean(td)\n",
    "    # print\n",
    "    # mk_slope, mk_p, lin_slope, lin_p = give_trends(td)\n",
    "    data[0,i] = (w/m)*100\n",
    "#     sig[0,i] = lin_p\n",
    "    \n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'DJF')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    w = np.std(td)\n",
    "    m = np.mean(td)\n",
    "    data[1,i] = (w/m)*100\n",
    "#     sig[0,i] = lin_p\n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'MAM')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    w = np.std(td)\n",
    "    m = np.mean(td)\n",
    "    data[2,i] = (w/m)*100\n",
    "\n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'JJA')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    w = np.std(td)\n",
    "    m = np.mean(td)\n",
    "    data[3,i] = (w/m)*100\n",
    "    \n",
    "    td = tdat\n",
    "    td = td.wspd10m.sel(time_counter=(td['time_counter.season'] == 'SON')).\\\n",
    "    groupby('time_counter.year').mean().values\n",
    "    w = np.std(td)\n",
    "    m = np.mean(td)\n",
    "    data[4,i] = (w/m)*100\n",
    "    \n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "                  index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "# df2 = pd.DataFrame(sig, columns=['NCEP-NCAR','NCEP-DOE','MERRA','JRA3Q','ERA5','UKESM'],\\\n",
    "#                   index  = ['full year','DJF','MAM', 'JJA', 'SON',])\n",
    "\n",
    "df.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "df.to_csv(f'./plts/IAV_1980-2019.csv')\n",
    "# df2.attrs = {\"made in\": 'plottingCode/Fig-means-extremes.ipynb'}\n",
    "# df2.to_csv(f'./plts/mn_wspd_trendsig-1980-2019.csv')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee12d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747b658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
